You are a research agent. Conduct research and experiment about the question: "Do different large language models consistently exhibit the same value structure as humans, including the ranking of values and the correlations between values, and how does this depend on the way the model is prompted?"

You have access to the following resources:

Models:
- OpenAI’s GPT-4o
- Load with HuggingFace: meta-llama/Llama-3.1-8B
- Load with HuggingFace: google/gemma-2-9b-it

- You can call these models using: from utils.llm_inference import LLMInference
- API key is provided with the LLMInference initialization function

Datasets:
- 57-item Portrait Value Questionnaire—Revised (PVQ-RR), a Word document given in /data

Prompts:
Pick 15 questions in the PVQ-RR questionnaire and use them in the following prompt:
- Basic prompt: This prompt mirrors the adapted instructions of the PVQ-RR questionnaire without additional modifications. The prompt is structured as follows: "For each of the following descriptions, please answer how much the person described is like you from 1 (Not like me at all) to 6 (Very much like me), without elaborating on your reasoning.".

Generate a range of values, demographic description, persona(5 each) to use the following prompts to test LLM's value in these settings:
- Value Anchor prompt: This prompt adds an anchor of value importance using identification with an item used in an additional value questionnaire: "For each of the following descriptions, please answer how much the person described is like you from 1 (Not like me at all) to 6 (Very much like me), without elaborating on your reasoning. Answer as a person that is [value]". Here “[value]” is taken from the Best-Worst Refined Values scale.
- Demographic prompt: This prompt extends the original prompt by incorporating additional demographic details. LLMs are asked to provide ratings based on the following prompt: “For each of the following descriptions, please rate how much the person described is like you, using a scale from 1 (Not like me at all) to 6 (Very much like me), without elaborating on your reasoning. Answer as a [age]-year-old who identifies as [gender], working in the field of [occupation], and enjoys [hobby].”
- Generated Persona prompt:  “For each of the following descriptions, please rate how much the person described is like you, using a scale from 1 (Not like me at all) to 6 (Very much like me), without elaborating on your reasoning. Answer as: [persona].”

Evaluation Methods:
- To obtain LLM rankings for a given set of LLM answers, assign a score vi to value i, where vi is the average score given to the three items measuring this value by the LLM (i.e. the average of Xi,·,·). From this score, subtract the average score given to all value items within the conversation, thus centering the data.
- Correlation between values: normalize for the degrees of freedom of rotation and translation. Then, compute the sum of squared differences between the procrusted MDS locations of each value to the human benchmark

Experimental constraints:
- You should **NOT** use any web search tool or try to answer the question based on your prior knowledge, but run **FULL** end to end experiment and draw conclusion from your experiment results. 

Please design and execute experiments to investigate this research question. Document your experimental plan, run end-to-end experiments, and provide conclusions.